<html><head><title>sqlscope</title>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" >
</head>
<body class='pod'>
<!--
  generated by Pod::Simple::HTML v3.23,
  using Pod::Simple::PullParser v3.23,
  under Perl v5.016002 at Fri Apr  3 18:11:30 2015 GMT.

 If you want to change this HTML document, you probably shouldn't do that
   by changing it directly.  Instead, see about changing the calling options
   to Pod::Simple::HTML, and/or subclassing Pod::Simple::HTML,
   then reconverting this document from the Pod source.
   When in doubt, email the author of Pod::Simple::HTML for advice.
   See 'perldoc Pod::Simple::HTML' for more info.

-->

<!-- start doc -->
<a name='___top' class='dummyTopAnchor' ></a>

<h1><a class='u'
name="NAME"
>NAME</a></h1>

<p>sqlscope - sql feature extractor</p>

<h1><a class='u'
name="SYNOPSIS"
>SYNOPSIS</a></h1>

<p>sqlscope -i &#60;inputfile&#62; -o &#60;outputfile&#62; -r &#39;QUERYNUM,QUERY&#39; -w &#39;TABLE_COMPARISON_VECTOR,QUERY&#39; -v 3 -c &#39;QUERYNUM&#39; -t &#60;totalsfile&#62; -g &#60;groupingsfile&#62; -f &#60;tablefile&#62;</p>

<p>options in the example: -i &#60;inputfile&#62; - the input file,
a CSV containing at least the queries to be processed,
if missing uses STDIN -o &#60;outputfile&#62; - the output file a CSV containing fields from the input plus features,tables used and query structure,
if missing uses STDOUT -r &#39;QUERYNUM,QUERY&#39; - the fields on the input...
must have at least QUERY the names given will be used for other switches,
if missing,
assumes just QUERY -w &#39;TABLE_COMPARISON_VECTOR,QUERY&#39; - the fields to output,
the full list of opions are given below ,
if missing,
writes ALL fields -v 3 - the verbosity of output,
0-7 with 7 being the maximum -c &#39;QUERYNUM&#39; - coalesces multiple rows into asingle SQL statement,
using the given list of fields to decide when to start a new SQL statement -t &#60;totalfile&#62; - file to write various counts to,
specified in a groupfile (next option)...
t &#38; g must be used together (it catches this) -g &#60;groupfile&#62; - an ini file that allows you to name aggregates (counts) and specify the &#34;group by&#34; fields to use.</p>

<h1><a class='u'
name="OPTIONS"
>OPTIONS</a></h1>

<h2><a class='u'
name="-i_&#60;inputfile&#62;_optional"
>-i &#60;inputfile&#62; optional</a></h2>

<p>The input file,
a CSV containing at least the queries to be processed,
if missing uses STDIN.
The CSV details can be configured with the -d -s -q -e switches and the -r switch is used to determine the contents of the CSV fields.</p>

<h2><a class='u'
name="-o_&#60;outputfile&#62;_optional"
>-o &#60;outputfile&#62; optional</a></h2>

<p>The output file,
a CSV that can then be processed further using other tools,
including viewing in a spreadsheet or loading to a database.
The fields in the output are determined by the -r switch.
If it is opitted,
it defaults to writing out all of the available fields (including the input,
individual features and four &#34;vectors&#34;.
For individual features,
the value is a count of the number of times a regular expression for that features caugh something.
This does NOT necessarily correlate exactly to the number of instances of a feature that you would see looking at the SQL.
The vectors are:</p>

<p>FEATURE_VECTOR - An array of counts representing the counts of features present.
The key is that it is consistently ordered,
so that queries&#39; &#34;similarity&#34; can be assessed.</p>

<p>&#39;FEATURE_VECTOR&#39; =&#62; &#39;048000000000060000001000003000000001004000000003000024000000002039018000018000000000000000&#39;</p>

<p>TABLE_VECTOR - An array of space separated tablenames that appear in the SQL.</p>

<p>&#39;TABLE_VECTOR&#39; =&#62; &#39;AC2T0010_CLAIM AC2T0060_SUMMARY&#39;</p>

<p>TABLE_COMPARISON_VECTOR - An array of single digit flags that indicate the presence or absense of a tablename in a query.
It is sorted by table name alphabetically.</p>

<p>&#39;TABLE_COMPARISON_VECTOR&#39; =&#62; &#39;1000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000&#39;</p>

<p>STRUCTURE_VECTOR - A translation of an SQL statement into a more compact and abstract form that can be used to identify &#34;similar&#34; queries in a different way.
Many statment components like &#34;SELECT&#34; are replaced with a single letter,
generally parentheses and comparison operators are preserved as well.
Most other stuff is elided.
The result is an avstract notion of the structure of an SQL statement that can be compared to other statements.
Interestingly it can sometimes be used to identify queries that were built similarly even when to human eyes the similarity is obscured in the full query text.
Many databases have one or more textual similarty algorithms that identify the minimum set of edits between one string and another.
When combined with these structure vectors,
this is very close to our intuitive notion of similar for SQL queries.
In the example below the structure vector translates as &#34;Select From Where = oRder&#34;.</p>

<p>&#34;SELECT * FROM _v_odbc_gettypeinfo1 WHERE data_type = -2 ORDER BY data_type,
type_name&#34; yields &#34;SFW=R,&#34;</p>

<h2><a class='u'
name="-x"
>-x</a></h2>

<p>Excludes rows that do not have a table that matches the table list.
This helps to reduce the output.</p>

<h2><a class='u'
name="-r_&#39;fieldlist&#39;_optional"
>-r &#39;fieldlist&#39; optional</a></h2>

<p>A list of the fields to be read from the input,
the names given will be used for specifying output,
totals and keys for coalescing queries.
The list is comma or colon separated and is NOT case sensitive.
There must be at least one column named QUERY.
If no read format is specified,
then a single field QUERY is assumed.</p>

<p>-r &#39;NPSID,NPSINSTANCEID,OPID,SESSIONID,sequenceid,USERNAME,SUBMITTIME,FINISHTIME,DBNAME,QUERY&#39;</p>

<pre>        -r &#39;QUERYNUM,QUERY&#39; - the fields on the input... must have at least QUERY the names given will be used for other switches, if missing, assumes just QUERY
        -w &#39;TABLE_COMPARISON_VECTOR,QUERY&#39; - the fields to output, the full list of opions are given below , if missing, writes ALL fields
        -v 3 - the verbosity of output, 0-7 with 7 being the maximum
        -c &#39;QUERYNUM&#39; - coalesces multiple rows into asingle SQL statement, using the given list of fields to decide when to start a new SQL statement
        -t &#60;totalfile&#62; - file to write various counts to, specified in a groupfile (next option)... t &#38; g must be used together (it catches this)
        -g &#60;groupfile&#62; - an ini file that allows you to name aggregates (counts) and specify the &#34;group by&#34; fields to use.</pre>

<h1><a class='u'
name="DESCRIPTION"
>DESCRIPTION</a></h1>

<p>sqlscope is a tool for analyzing SQL statements such as those a database or query tool might log. It assumes a character separated value format for the file that contains the queries to be analyzed and provides options for changing the separators, the quote and escape characters. sqlscope uses simple regular expressions to identify features to allow it to handle multiple SQL dialects and query fragments and to be easily extended to identify more complex structures in SQL, such as equality statements that compare to state codes. The tradeoff for this simplicity is that its feature matching can be relatively easily fooled into false positives (the reverse is much rarer).</p>

<p>sqlscope requires at minimum, a list of tables to look for and a list of queries to process.</p>

<p>An input file might look like:</p>

<p>1,50,2436209,418374,-1,DIRKSA1,2011-08-04 03:21:50.500478,2011-08-04 03:21:50.500665,PCIT_AIMZ_VIEWS,set nz_encoding to &#39;utf8&#39; 1,50,2436210,418374,-1,DIRKSA1,2011-08-04 03:21:50.501566,2011-08-04 03:21:50.501657,PCIT_AIMZ_VIEWS,set DateStyle to &#39;ISO&#39; 1,50,2436211,418374,-1,DIRKSA1,2011-08-04 03:21:50.503513,2011-08-04 03:21:50.503835,PCIT_AIMZ_VIEWS,&#34;select version(), &#39;ODBC Client Version: Release 4.6.8 [Build 13111]&#39;, &#39;32-bit&#39;, &#39;OS Platform: SunOS&#39;, &#39;OS Username: hpsprod&#39;&#34; 1,50,2436212,418374,-1,DIRKSA1,2011-08-04 03:21:50.587112,2011-08-04 03:21:50.591474,PCIT_AIMZ_VIEWS,select feature from _v_odbc_feature where spec_level = &#39;3.5&#39; 1,50,2436214,418374,-1,DIRKSA1,2011-08-04 03:21:50.727336,2011-08-04 03:21:50.731826,PCIT_AIMZ_VIEWS,&#34;SELECT * FROM _v_odbc_gettypeinfo1 WHERE data_type = -2 ORDER BY data_type, type_name&#34;</p>

<p>A table file might look like:</p>

<p>AC2T0010_CLAIM AC2T0020_WC_CLMNT AC2T0021_BDYPRT_CD AC2T0022_CAUSE_CD AC2T0023_INJURY_CD AC2T0024_NATURE_CD AC2T0030_COVERAGE AC2T0031_COV_DESC</p>

<p>The commandline to process this might look like:</p>

<p>cat input.sql | sqlscope -f scopetables.csv -r &#39;NPSID,NPSINSTANCEID,OPID,SESSIONID,sequenceid,USERNAME,SUBMITTIME,FINISHTIME,DBNAME,QUERY&#39; -v 7 | more</p>

<p>The above commandline will produce extremely verbose debugging output to STDERR (-v 7) as well as the following output to STDIN:</p>

<p>1,50,2436209,418374,-1,DIRKSA1,&#34;2011-08-04 03:21:50.500478&#34;,&#34;2011-08-04 03:21:50.500665&#34;,PCIT_AIMZ_VIEWS,&#34;set nz_encoding to &#39;utf8&#39;&#34;,,,000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000,0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 1,50,2436210,418374,-1,DIRKSA1,&#34;2011-08-04 03:21:50.501566&#34;,&#34;2011-08-04 03:21:50.501657&#34;,PCIT_AIMZ_VIEWS,&#34;set DateStyle to &#39;ISO&#39;&#34;,,,000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000,0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 1,50,2436211,418374,-1,DIRKSA1,&#34;2011-08-04 03:21:50.503513&#34;,&#34;2011-08-04 03:21:50.503835&#34;,PCIT_AIMZ_VIEWS,&#34;select version(), &#39;ODBC Client Version: Release 4.6.8 [Build 13111]&#39;, &#39;32-bit&#39;, &#39;OS Platform: SunOS&#39;, &#39;OS Username: hpsprod&#39;&#34;,,&#34;SN(),,,,&#34;,000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000,0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 1,50,2436212,418374,-1,DIRKSA1,&#34;2011-08-04 03:21:50.587112&#34;,&#34;2011-08-04 03:21:50.591474&#34;,PCIT_AIMZ_VIEWS,&#34;select feature from _v_odbc_feature where spec_level = &#39;3.5&#39;&#34;,1,1,,SFW=,000000000000001000000000000000000000000000000000000000000000000001000000000000000000000000,0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 1,50,2436214,418374,-1,DIRKSA1,&#34;2011-08-04 03:21:50.727336&#34;,&#34;2011-08-04 03:21:50.731826&#34;,PCIT_AIMZ_VIEWS,&#34;SELECT * FROM _v_odbc_gettypeinfo1 WHERE data_type = -2 ORDER BY data_type, type_name&#34;,2,1,1,1,,&#34;SFW=R,&#34;,000000000000002000000000000000000000000000000000000000000000000001001000001000000000000000,0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000</p>

<h1><a class='u'
name="DIAGNOSTICS_and_MODIFICATION"
>DIAGNOSTICS and MODIFICATION</a></h1>

<p>Every effort has been made to have reasonably informative error messages for common issues. The switch -v 7 will produce voluminous debugging output.</p>

<p>When you are modifying the internal regular expressions for whatever purpose, turning on the debugging output will allow you to see what the regexes are capturing:</p>

<p>2012/08/17 17:33:04 CSV parsed input line:$VAR1 = [ &#39;SELECT SUM(COLUMN1), COUNT(*) as CNT FROM TABLE1&#39; ]; 2012/08/17 17:33:04 Feature Test: MULTIPLE_WILDCARD :$VAR1 = []; 2012/08/17 17:33:04 Feature Test: EXPLICIT_RANGE_QUERY :$VAR1 = []; 2012/08/17 17:33:04 Feature Test: UNION_STATEMENT :$VAR1 = []; 2012/08/17 17:33:04 Feature Test: AGGREGATION :$VAR1 = [ &#39; SUM(&#39;, &#39; COUNT(&#39; ]; 2012/08/17 17:33:04 Feature Test: CONTAINS_SELECT_STATEMENT :$VAR1 = []; 2012/08/17 17:33:04 Feature Test: MANY_LITERALS :$VAR1 = []; 2012/08/17 17:33:04 Feature Test: LOGICAL_AND :$VAR1 = []; 2012/08/17 17:33:04 Feature Test: UPDATE_STATEMENT :$VAR1 = []; 2012/08/17 17:33:04 Feature Test: ANSI_RIGHT_OUTER_JOIN :$VAR1 = []; 2012/08/17 17:33:04 Feature Test: ANSI_LEFT_OUTER_JOIN :$VAR1 = []; 2012/08/17 17:33:04 Feature Test: WINDOW_QUERY :$VAR1 = []; 2012/08/17 17:33:04 Feature Test: COUNT :$VAR1 = [ &#39; COUNT(&#39; ];</p>

<p>The most common issue seems to be having the number of matched items not matching expectations... So looking at the AGGREGATION expression:</p>

<p>,&#39;AGGREGATION&#39;=&#62; qr{((?:[ ,(+\-*/]SUM[ (])|(?:[ ,(+\-*/]MIN[ (])|(?:[ ,(+\-*/]MAX[ (])|(?:[ ,(+\-*/]AVG[ (])|(?:[ ,(+\-*/]COUNT[ (]))}i</p>

<p>The expression originally returned several undefined items in addition to the SUM and count shown above. Adding (?: into each of the regex groupings below the top level eliminated the false positives.</p>

<p>So what does this actually produce in output?</p>

<p>002000000 ... as you would expect!</p>

<p>If you want to add your own features, just edit the perl code and add lines similar to the AGGREGATION line you see above. The leading comma is required. Because the regexes are evaluated in isolation, there is no interaction between them (see I TOLD you it was simple!).</p>

<h1><a class='u'
name="SEE_ALSO"
>SEE ALSO</a></h1>

<h1><a class='u'
name="LICENSE"
>LICENSE</a></h1>

<!-- end doc -->

</body></html>
